---
layout: post
category : 笔记
tags : [DL, NLP]
---
{% include JB/setup %}

## Deep Learning for NLP(without Magic)

**笔记**

目前机器学习基于人工设计的特征，机器学习只是优化参数权重已达到好的预测效果。

表示学习：尝试自动学习好的特征来表示数据

深度学习：尝试学习多层的表示，以增加复杂度和抽象度。

研究深度学习的五个原因：

1. 表示性学习：手工设计特征复杂耗时

2. distributed representation的必要性：NLP中原子表示法的脆弱性。

   基于聚类的Distribional similarity效果很好：

   * 语法分析 **Brown clustering**

   * 实体识别 **Standford NER, exchange clustering**
   
   Distributed representations可处理维数灾难。
